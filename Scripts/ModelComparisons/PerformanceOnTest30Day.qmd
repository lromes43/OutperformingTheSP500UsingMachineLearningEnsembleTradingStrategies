---
title: "Untitled"
format: html
---

Want to see how model preforms on the training data



```{python}
import pandas as pd
test = pd.read_feather("/Users/lukeromes/Desktop/Personal/Sp500Project/Data/TestData.feather")


```

Loading in models

```{python}
binaryone = joblib.load("/Users/lukeromes/Desktop/Personal/Sp500Project/Models/FinalBoostedOneDayClassifier.joblib")
continuousone = joblib.load("/Users/lukeromes/Desktop/Personal/Sp500Project/Models/ContinuousOneDayFinal.job.lib")
binaryfive = joblib.load("/Users/lukeromes/Desktop/Personal/Sp500Project/Models/FinalBoostedFiveDayClassifier.joblib")
continuousfive = joblib.load("/Users/lukeromes/Desktop/Personal/Sp500Project/Models/ContinuousFiveDayFinal.joblib")
binarythirty = joblib.load("/Users/lukeromes/Desktop/Personal/Sp500Project/Models/FinalBoostedThirtyDayClassifier.joblib")
continuousthirty = joblib.load("/Users/lukeromes/Desktop/Personal/Sp500Project/Models/ContinuousThirtyDayFinal.joblib")
```



Transform data to correct format for models

30 Binary

Only need dtest
```{python}
import pandas as pd
import xgboost as xgb

drop_cols = ['Date', 'next_day_pct_change','Daily_Return',
 'next_5_day_pct_change',
 'Movement_5_day',
 'next_30_day_pct_change',
 'Movement_30_day',
 'Movement']

X = test.drop(drop_cols, axis = 1)
X_final = pd.get_dummies(X, drop_first=True)
actual = test['Movement_30_day'].astype(int)

dtest = xgb.DMatrix(X_final, label = actual)
```


```{python}
binaryone = joblib.load("/Users/lukeromes/Desktop/Personal/Sp500Project/Models/FinalBoostedOneDayClassifier.joblib")

# Print the feature names and their required order
required_features = binaryone.feature_names
print("--- Required Feature Order ---")
for i, feature in enumerate(required_features):
    print(f"{i+1:03d}: {feature}")

```




Predict on new data binary
```{python}


pred = binaryone.predict(dtest)
pred_final = (pred >=.5).astype(int)

cm = confusion_matrix(actual, pred_final)
finalboostedcm = ConfusionMatrixDisplay(confusion_matrix=cm)
finalboostedcm.plot(cmap = "Blues")
plt.title("Final Boosted Confusion Matrix")
plt.show()
final_boosted_acc = accuracy_score(actual, pred_final)
print(final_boosted_acc)

#Getting 55.647



pred_final_df = pd.DataFrame(pred_final)
pred_final_df = pred_final_df.reset_index().rename(columns={'index': 'iteration', 0: 'actual up/down'})
actual = actual.reset_index().rename(columns={'index': 'iteration'})
merged_binary = pd.merge(pred_final_df, actual, how='inner', on='iteration')
sorted_ticker_series = transformed_data['Ticker'].sort_values(ascending=True)
merged_binary['ticker'] = sorted_ticker_series.reset_index(drop=True)
merged_binary_thirty = merged_binary

```


thirty Day Continuous

```{python}
X = test.drop(['Date',
    'next_day_pct_change','next_5_day_pct_change',
    'Movement_5_day','next_30_day_pct_change',
    'Movement_30_day','Movement'
], axis=1)

if 'Date' in X.columns:
    X['Date'] = pd.to_datetime(X['Date']).view('int64')


X_raw = pd.get_dummies(X, drop_first=True)

required_features = continuousone.feature_names
X_final = X_raw.reindex(columns=required_features, fill_value=0)

X_final = X_final.apply(pd.to_numeric, errors='coerce').fillna(0)
y_final = test['next_30_day_pct_change'].astype(float)

dtest = xgb.DMatrix(X_final)

```


```{python}
y_pred_one = continuousone.predict(dtest)
y_test_new = y_final.reset_index()
y_test_new = y_test_new.reset_index().drop('index', axis =1).rename(columns = {'level_0':'iteration', 'next_day_pct_change': 'actual'})
MAE_df = pd.DataFrame(y_pred_one).reset_index().rename(columns = {'index': 'iteration', 0 : 'Initial_Predicted'})
merged = pd.merge(y_test_new, MAE_df, how = 'inner', on = 'iteration')


merged['Initial_Predicted'] = merged['Initial_Predicted'] * 100 


sorted_ticker_series = test['Ticker'].sort_values(ascending=True)
merged['ticker'] = sorted_ticker_series.reset_index(drop=True)
merged_cont_thirty = merged 
merged_cont_thirty = merged_cont_thirty.rename(columns = {'next_30_day_pct_change': 'actual'})
```


```{python}

squared_errors = (merged_cont_thirty ['actual'] - merged_cont_thirty['Initial_Predicted']) ** 2

MSE = squared_errors.mean()
MSE_percent = MSE * 100

print(f"MSE: {MSE}")
print(f"MSE_percent: {MSE_percent}")


one_day_rmse = np.sqrt(MSE) 
one_day_rmse_percent = one_day_rmse * 100

print(f" one day rmse: {one_day_rmse}")
print(f"one day rmse percent: {one_day_rmse_percent}")

threshold = 0.5 
close_accuracy = np.mean(np.abs(merged_cont_thirty['actual'] - merged_cont_thirty ['Initial_Predicted']) <= threshold)
print(f"Within ±0.5% accuracy (in percentage points): {close_accuracy}")
```

MSE: 0.011510008088852445
MSE_percent: 1.1510008088852446
 one day rmse: 0.10728470575460626
one day rmse percent: 10.728470575460626
Within ±0.5% accuracy (in percentage points): 0.398052738336714





```{python}
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, roc_auc_score


y_true_binary = test['Movement_30_day'].astype(int) 


probabilities = pred 


auc_score = roc_auc_score(y_true_binary, probabilities)
print(f"\nArea Under the Curve (AUC) for 30-Day Movement: {auc_score:.4f}")


fpr, tpr, thresholds = roc_curve(y_true_binary, probabilities)


plt.figure(figsize=(8, 6))

plt.plot(fpr, tpr, color='navy', lw=2, label=f'ROC curve (AUC = {auc_score:.4f})')

plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--', label='Random Classifier')

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate (1 - Specificity)')
plt.ylabel('True Positive Rate (Sensitivity/Recall)')
plt.title('ROC Curve for 30-Day Movement Prediction')
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

```


